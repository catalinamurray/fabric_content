{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8f67112",
   "metadata": {},
   "source": [
    "## Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224cdcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statistics\n",
    "import random\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f398023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 19:14:43.927077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71151257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.feature import graycomatrix, graycoprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f55351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d04d48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a12fb1",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98e88878",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('data_h5','r')\n",
    "\n",
    "denim_blended = h5f['denim_blended'][:]\n",
    "denim = h5f['denim'][:]\n",
    "\n",
    "knit_blended = h5f['knit_blended'][:]\n",
    "knit = h5f['knit'][:]\n",
    "\n",
    "fleece_blended = h5f['fleece_blended'][:]\n",
    "fleece_poly = h5f['fleece_poly'][:]\n",
    "fleece_Modal = h5f['fleece_Modal'][:]\n",
    "\n",
    "linen = h5f['linen'][:]\n",
    "linen_rayon = h5f['linen_rayon'][:]\n",
    "linen_viscose = h5f['linen_viscose'][:]\n",
    "\n",
    "leather_poly = h5f['leather_poly'][:]\n",
    "leather_PU = h5f['leather_PU'][:]\n",
    "leather_PVC = h5f['leather_PVC'][:]\n",
    "\n",
    "outdoor_cotton = h5f['outdoor_cotton'][:]\n",
    "outdoor_poly = h5f['outdoor_poly'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c99a74",
   "metadata": {},
   "source": [
    "# Preprocess Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a8eba6",
   "metadata": {},
   "source": [
    "### 1. Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0be2a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be np array (#imgs, pixel,pixel,1) for grey scale\n",
    "def rotate_imgs (fabric, num_imgs, angle_start, angle_stop): \n",
    "    \n",
    "    pixels = len(fabric[1,:,:,0]) \n",
    "    fabric_aug = np.zeros((num_imgs,pixels,pixels,3))\n",
    "    \n",
    "    for i in range(num_imgs): \n",
    "        angle = random.randint(angle_start, angle_stop)\n",
    "        # ImageDataGenerator rotation\n",
    "        datagen = ImageDataGenerator(rotation_range=angle, fill_mode='nearest')\n",
    "        # iterator\n",
    "        aug_iter = datagen.flow(fabric, batch_size=1)\n",
    "        # generate one img with random angle\n",
    "        image = next(aug_iter)[0].astype('uint8')\n",
    "        fabric_aug[i,:,:,:] = image\n",
    " \n",
    "    return fabric_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ce5f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be np array (#imgs, pixel,pixel,1) for grey scale\n",
    "def shift_imgs (fabric, num_imgs, width_shift, height_shift): \n",
    "    \n",
    "    pixels = len(fabric[1,:,:,0]) \n",
    "    fabric_aug = np.zeros((num_imgs,pixels,pixels,3))\n",
    "    \n",
    "    for i in range(num_imgs): \n",
    "        width_shift = random.uniform(0.01, width_shift)\n",
    "        height_shift = random.uniform(0.01, height_shift)\n",
    "        # ImageDataGenerator rotation\n",
    "        datagen = ImageDataGenerator(width_shift_range=width_shift, height_shift_range=height_shift)\n",
    "        # iterator\n",
    "        aug_iter = datagen.flow(fabric, batch_size=1)\n",
    "        # generate one img with random angle\n",
    "        image = next(aug_iter)[0].astype('uint8')\n",
    "        fabric_aug[i,:,:,:] = image\n",
    " \n",
    "    return fabric_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9237192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be np array (#imgs, pixel,pixel,1) for grey scale\n",
    "def flip_imgs (fabric, num_imgs): \n",
    "    \n",
    "    pixels = len(fabric[1,:,:,0]) \n",
    "    fabric_aug = np.zeros((num_imgs,pixels,pixels,3))\n",
    "    \n",
    "    for i in range(num_imgs): \n",
    "        # ImageDataGenerator rotation\n",
    "        datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "        # iterator\n",
    "        aug_iter = datagen.flow(fabric, batch_size=1)\n",
    "        # generate one img with random angle\n",
    "        image = next(aug_iter)[0].astype('uint8')\n",
    "        fabric_aug[i,:,:,:] = image\n",
    " \n",
    "    return fabric_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bd0df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be np array (#imgs, pixel,pixel,1) for grey scale\n",
    "def zoom_imgs (fabric, num_imgs, start_range, stop_range): \n",
    "    \n",
    "    pixels = len(fabric[1,:,:,0]) \n",
    "    fabric_aug = np.zeros((num_imgs,pixels,pixels,3))\n",
    "    \n",
    "    for i in range(num_imgs): \n",
    "        zoom = random.uniform(start_range,stop_range)\n",
    "        #stop = random.uniform(start_range+.01, stop_range)\n",
    "        # ImageDataGenerator rotation\n",
    "        datagen = ImageDataGenerator(zoom_range=zoom)\n",
    "        # iterator\n",
    "        aug_iter = datagen.flow(fabric, batch_size=1)\n",
    "        # generate one img with random angle\n",
    "        image = next(aug_iter)[0].astype('uint8')\n",
    "        fabric_aug[i,:,:,:] = image\n",
    " \n",
    "    return fabric_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6866815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_fabric(fabric):\n",
    "    \n",
    "    #num_imgs = len(fabric)\n",
    "    num_imgs = 5\n",
    "    pixels = len(fabric[1,:,:,0])\n",
    "    \n",
    "    rotate = rotate_imgs(fabric, num_imgs, -15, 15)\n",
    "    shift = shift_imgs(fabric, num_imgs, 0.2, 0.2)\n",
    "    flip = flip_imgs(fabric, num_imgs)\n",
    "    zoom = zoom_imgs(fabric, num_imgs, 0.05, 1)\n",
    "    \n",
    "    transform = np.zeros((4*num_imgs,pixels,pixels,3))\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while j<(4*num_imgs):\n",
    "        transform[j,:,:] = rotate[i]\n",
    "        transform[j+1,:,:] = shift[i]\n",
    "        transform[j+2,:,:] = flip[i]\n",
    "        transform[j+3,:,:] = zoom[i]\n",
    "        j+=4\n",
    "        i+=1\n",
    "       \n",
    "    return transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d7a485",
   "metadata": {},
   "source": [
    "### Add augmented data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "356d45b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "denim_blended_aug = transform_fabric(denim_blended)\n",
    "denim_blended = np.vstack((denim_blended_aug, denim_blended))\n",
    "denim_aug = transform_fabric(denim)\n",
    "denim = np.vstack((denim, denim_aug))\n",
    "\n",
    "knit_blended_aug = transform_fabric(knit_blended)\n",
    "knit_blended = np.vstack((knit_blended_aug, knit_blended))\n",
    "knit_aug = transform_fabric(knit)\n",
    "knit = np.vstack((knit, knit_aug))\n",
    "\n",
    "fleece_blended_aug = transform_fabric(fleece_blended)\n",
    "fleece_blended = np.vstack((fleece_blended_aug, fleece_blended))\n",
    "fleece_poly_aug = transform_fabric(fleece_poly)\n",
    "fleece_poly = np.vstack((fleece_poly, fleece_poly_aug))\n",
    "fleece_Modal_aug = transform_fabric(fleece_Modal)\n",
    "fleece_Modal = np.vstack((fleece_Modal, fleece_Modal_aug))\n",
    "\n",
    "\n",
    "linen_aug = transform_fabric(linen)\n",
    "linen_blended = np.vstack((linen_aug, linen))\n",
    "linen_rayon_aug = transform_fabric(linen_rayon)\n",
    "linen_rayon = np.vstack((linen_rayon, linen_rayon_aug))\n",
    "linen_viscose_aug = transform_fabric(linen_viscose)\n",
    "linen_viscose = np.vstack((linen_viscose, linen_viscose_aug))\n",
    "\n",
    "leather_poly_aug = transform_fabric(leather_poly)\n",
    "leather_poly = np.vstack((leather_poly_aug, leather_poly))\n",
    "leather_PU_aug = transform_fabric(leather_PU)\n",
    "leather_PU = np.vstack((leather_PU, leather_PU_aug))\n",
    "leather_PVC_aug = transform_fabric(leather_PVC)\n",
    "leather_PVC = np.vstack((leather_PVC, leather_PVC_aug))\n",
    "\n",
    "outdoor_cotton_aug = transform_fabric(outdoor_cotton)\n",
    "outdoor_cotton = np.vstack((outdoor_cotton, outdoor_cotton_aug))\n",
    "outdoor_poly_aug = transform_fabric(outdoor_poly)\n",
    "outdoor_poly = np.vstack((outdoor_poly, outdoor_poly_aug))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452c3797",
   "metadata": {},
   "source": [
    "### Enhance images with histogram equlaization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef3f7940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cdad424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gray_imgs(fabric):\n",
    "    num_imgs = len(fabric)\n",
    "    gray = np.zeros((num_imgs, 224, 224))\n",
    "    for i in range(num_imgs):\n",
    "        gray[i,:,:] = rgb2gray(fabric[i,:,:,:])\n",
    "    return gray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44aa4bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_img(image): \n",
    "    image = rgb2gray(image)\n",
    "    image = image/255\n",
    "    img_adapteq = exposure.equalize_adapthist(image, clip_limit=0.03) #tried clip_limit=[0.1-1.0] (0.5 was best) too grainy if you go up very soft going down \n",
    "    \n",
    "    return img_adapteq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6971bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_fabric(fabric): \n",
    "    N,p,p,c = fabric.shape \n",
    "    equalized = np.zeros((N,p,p))\n",
    "    for n in range(N):\n",
    "        image = fabric[n,:,:,:]\n",
    "        equalized[n,:,:] = equalize_img(image)\n",
    "        \n",
    "    return equalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bd5cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "denim_eq = equalize_fabric(denim)\n",
    "denim_b_eq = equalize_fabric(denim_blended)\n",
    "\n",
    "\n",
    "knit_eq = equalize_fabric(knit)\n",
    "knit_b_eq = equalize_fabric(knit_blended)\n",
    "\n",
    "\n",
    "fleece_blended_eq = equalize_fabric(fleece_blended)\n",
    "fleece_poly_eq = equalize_fabric(fleece_poly)\n",
    "fleece_Modal_eq = equalize_fabric(fleece_Modal)\n",
    "\n",
    "\n",
    "linen_eq = equalize_fabric(linen)\n",
    "linen_rayon_eq = equalize_fabric(linen_rayon)\n",
    "linen_viscose_eq = equalize_fabric(linen_viscose)\n",
    "\n",
    "\n",
    "leather_poly_eq = equalize_fabric(leather_poly)\n",
    "leather_PU_eq = equalize_fabric(leather_PU)\n",
    "leather_PVC_eq = equalize_fabric(leather_PVC)\n",
    "\n",
    "\n",
    "outdoor_cotton_eq = equalize_fabric(outdoor_cotton)\n",
    "outdoor_poly_eq = equalize_fabric(outdoor_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7336f",
   "metadata": {},
   "source": [
    "## Combine data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3e458c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(fabric, label):\n",
    "    images = len(fabric)\n",
    "    labels = np.zeros((images))\n",
    "    for i in range(images):\n",
    "        labels[i] = label\n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b9bb97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_matrix_eq(num_fabrics,fabric1,fabric2,fabric3,fabric4): \n",
    "    \n",
    "    # create labels \n",
    "    fabric1_labels = create_labels(fabric1,0)\n",
    "    fabric2_labels = create_labels(fabric2,1)\n",
    "    \n",
    "    if num_fabrics ==2: \n",
    "        X = np.vstack((fabric1, fabric2))\n",
    "        Y = np.hstack((fabric1_labels, fabric2_labels))\n",
    "    \n",
    "    elif num_fabrics == 3: \n",
    "        fabric3_labels = create_labels(fabric3,2)\n",
    "        X = np.vstack((fabric1, fabric2, fabric3))\n",
    "        Y = np.hstack((fabric1_labels, fabric2_labels, fabric3_labels))\n",
    "  \n",
    "    return X, Y \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0b74b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_matrix(num_fabrics,fabric1,fabric2,fabric3,fabric4): \n",
    "    \n",
    "    # create gray images \n",
    "    fabric1_g = create_gray_imgs(fabric1)\n",
    "    fabric2_g = create_gray_imgs(fabric2)\n",
    "    \n",
    "    # create labels \n",
    "    fabric1_labels = create_labels(fabric1_g,0)\n",
    "    fabric2_labels = create_labels(fabric2_g,1)\n",
    "    \n",
    "    row = len(fabric1_g)\n",
    "    row2 = len(fabric1_labels)\n",
    "    \n",
    "    row3 = len(fabric2_g) \n",
    "    row4 = len(fabric2_labels)\n",
    "    \n",
    "    if num_fabrics == 2: \n",
    "        if row != row2: \n",
    "            print('error fabric1')\n",
    "        elif row3 != row4: \n",
    "            print ('error fabric 2')\n",
    "        else:\n",
    "            X = np.vstack((fabric1_g, fabric2_g))\n",
    "            Y = np.hstack((fabric1_labels, fabric2_labels))\n",
    "    \n",
    "    elif num_fabrics == 3: \n",
    "        fabric3_g = create_gray_imgs(fabric3)\n",
    "        fabric3_labels = create_labels(fabric3_g,2)\n",
    "        X = np.vstack((fabric1_g, fabric2_g, fabric3_g))\n",
    "        Y = np.hstack((fabric1_labels, fabric2_labels, fabric3_labels))\n",
    "        \n",
    "    elif num_fabrics == 4: \n",
    "        fabric3_g = create_gray_imgs(fabric3)\n",
    "        fabric3_labels = create_labels(fabric3_g,2)\n",
    "        fabric4_g = create_gray_imgs(fabric4)\n",
    "        fabric4_labels = create_labels(fabric4_g,3)\n",
    "        X = np.vstack((fabric1_g, fabric2_g, fabric3_g,fabric4_g))\n",
    "        Y = np.hstack((fabric1_labels, fabric2_labels, fabric3_labels, fabric4_labels))\n",
    "        \n",
    "    \n",
    "    return X, Y \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3886759",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fleece, Y_fleece = create_data_matrix_eq(3,fleece_blended_eq,fleece_poly_eq[0:90,:,:],fleece_Modal_eq,0)\n",
    "X_knit, Y_knit = create_data_matrix_eq(2,knit_b_eq, knit_eq, 0, 0)\n",
    "X_linen, Y_linen = create_data_matrix_eq(3,linen_eq,linen_rayon_eq, linen_viscose_eq,0)\n",
    "X_leather, Y_leather = create_data_matrix_eq(3,leather_poly_eq,leather_PU_eq, leather_PVC_eq, 0)\n",
    "X_outdoor, Y_outdoor = create_data_matrix_eq(2,outdoor_cotton_eq,outdoor_poly_eq, 0,0)\n",
    "X_denim, Y_denim = create_data_matrix_eq(2,denim_eq,denim_b_eq, 0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4d36a3",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c716f",
   "metadata": {},
   "source": [
    "### 1. LBP histograms  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84f360b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp_image(images,num_points,radius):\n",
    "    lbps = []\n",
    "    N, p, p = images.shape\n",
    "    for n in range(N):\n",
    "        lbp = local_binary_pattern(images[n,:,:], P=num_points, R=radius)\n",
    "        lbps.append(lbp)\n",
    "    \n",
    "    return np.array(lbps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0016dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add note about where code is from \n",
    "\n",
    "def show_images_with_labels(images, labels, start_index=0):\n",
    "    fig, axes = plt.subplots(ncols=7, nrows=1, figsize=(18, 2.5))\n",
    "\n",
    "    index = start_index\n",
    "    for i in range(7):\n",
    "        axes[i].imshow(images[index], cmap='gray')\n",
    "        axes[i].set_title([labels[index]])\n",
    "        axes[i].get_xaxis().set_visible(False)\n",
    "        axes[i].get_yaxis().set_visible(False)\n",
    "        index += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "304c9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_images(image, num_sub_imgs): \n",
    "    pixel, pixel = image.shape\n",
    "    total_imgs = round(num_sub_imgs**2)\n",
    "    sub_pixels = round(pixel/num_sub_imgs)\n",
    "    #for n in range(N): \n",
    "    start_row = 0\n",
    "    stop_row = start_row + sub_pixels\n",
    "    start_col = 0\n",
    "    stop_col = start_col +  sub_pixels\n",
    "    row = 0 \n",
    "    sub_imgs = np.zeros((total_imgs,sub_pixels,sub_pixels))\n",
    "    for i in range(total_imgs-1):\n",
    "        width = pixel/num_sub_imgs\n",
    "        sub_imgs[i,:,:] = image[start_row:stop_row,start_col:stop_col]\n",
    "        #change row \n",
    "        if stop_col ==224: \n",
    "            row = row+1 \n",
    "            start_col = 0\n",
    "            stop_col = start_col +  sub_pixels\n",
    "            start_row = row*(sub_pixels)\n",
    "            stop_row = start_row + sub_pixels \n",
    "        else: \n",
    "            start_col = start_col+sub_pixels\n",
    "            stop_col= stop_col + sub_pixels\n",
    "            \n",
    "    return sub_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3eec7702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_histograms(fabric,num_sub_imgs,bins_per_sub_images): \n",
    "    N,p,p = fabric.shape\n",
    "    fabric_hist = np.zeros((N,round(bins_per_sub_images*num_sub_imgs*num_sub_imgs)))\n",
    "    for n in range(N):\n",
    "        image = fabric[n,:,:]\n",
    "        sub_imgs = create_sub_images(image, num_sub_imgs)\n",
    "        sub_img_hist = []\n",
    "        for i in range(round(num_sub_imgs**2)): \n",
    "            histogram = np.histogram(sub_imgs[i,:,:], bins=bins_per_sub_images)[0]\n",
    "            sub_img_hist.append(histogram)\n",
    "            \n",
    "        hist1 = np.array(sub_img_hist).flatten()\n",
    "        fabric_hist[n,:] = hist1\n",
    "    \n",
    "    return fabric_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1feb8c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp_histograms(fabric, num_points, radius, num_sub_imgs, num_bins):\n",
    "    lbp = lbp_image(fabric,num_points,radius)\n",
    "    lbp_hist = create_histograms(lbp, num_sub_imgs, num_bins)\n",
    "    \n",
    "    return lbp_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cff812",
   "metadata": {},
   "source": [
    "### 2. GLCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8298717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GLCM_sub_imgs(sub_images, dist, angle): \n",
    "    sub_images = img_as_ubyte(sub_images/255)\n",
    "    num_images, pixel, pixel = sub_images.shape\n",
    "    contrast = []\n",
    "    dissimilarity = []\n",
    "    homogeneity = []\n",
    "    ASM = []\n",
    "    energy = []\n",
    "    correlation = []\n",
    "    for i in range(num_images): \n",
    "        glcm = graycomatrix(sub_images[i,:,:], distances = dist, angles = angle, levels = 256,\n",
    "                       symmetric = True, normed = True)\n",
    "        contrast.append(graycoprops(glcm, 'contrast'))\n",
    "        dissimilarity.append(graycoprops(glcm, 'dissimilarity'))\n",
    "        homogeneity.append(graycoprops(glcm, 'homogeneity'))\n",
    "        ASM.append(graycoprops(glcm, 'ASM'))\n",
    "        energy.append(graycoprops(glcm, 'energy'))\n",
    "        correlation.append(graycoprops(glcm, 'correlation'))\n",
    "    \n",
    "    return contrast, dissimilarity, homogeneity, ASM, energy, correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fb1c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GLCM_fabric(fabric, num_sub_imgs, dist, angle):\n",
    "    #fabric_g = create_gray_imgs(fabric)\n",
    "    N, pixels, pixels = fabric.shape\n",
    "    properties = np.zeros((N,6,round(num_sub_imgs**2)))\n",
    "    for n in range(N): \n",
    "        image = fabric[n, :, :]\n",
    "        sub_imgs = create_sub_images(image, num_sub_imgs)\n",
    "        contrast, dissimilarity, homogeneity, ASM, energy, correlation = GLCM_sub_imgs(sub_imgs,dist,angle)\n",
    "        for i in range(round(num_sub_imgs**2)): \n",
    "            properties[n,0,i]=contrast[i]\n",
    "            properties[n,1,i]=dissimilarity[i]\n",
    "            properties[n,2,i]=homogeneity[i]\n",
    "            properties[n,3,i]= ASM[i]\n",
    "            properties[n,4,i]= energy[i]\n",
    "            properties[n,5,i]=correlation[i]\n",
    "    \n",
    "    return properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60afb761",
   "metadata": {},
   "source": [
    "## 3. combine features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c6aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d474bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fabric_features(X, Y, numpoints, radius): \n",
    "    \n",
    "    #split data \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                       stratify = Y)\n",
    "    \n",
    "    #create lbp histograms \n",
    "    X_train_lbp = lbp_histograms(X_train, numpoints, radius, num_sub_imgs = 4, num_bins = 64) #tried 10 bins, 40 bins, 56 and 64 (drastically increased) \n",
    "    X_test_lbp = lbp_histograms(X_test, numpoints, radius, num_sub_imgs = 4, num_bins = 64)\n",
    "    \n",
    "    #create GCLM features \n",
    "    X_train_prop = GLCM_fabric(X_train, num_sub_imgs = 4, dist = [2], angle = [0])\n",
    "    N,K,L = X_train_prop.shape\n",
    "    X_train_prop = X_train_prop.reshape((N,K*L))\n",
    "    X_test_prop = GLCM_fabric(X_test, num_sub_imgs = 4, dist = [2] , angle = [0])\n",
    "    N,K,L = X_test_prop.shape\n",
    "    X_test_prop = X_test_prop.reshape((N,K*L))\n",
    "    \n",
    "    #combine features \n",
    "    X_train = np.hstack((X_train_lbp,X_train_prop))\n",
    "    X_test = np.hstack((X_test_lbp,X_test_prop))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7675c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fabric_features(X, Y, numpoints, radius)\n",
    "X_train_fleece, X_test_fleece, Y_train_fleece, Y_test_fleece = fabric_features(X_fleece, Y_fleece,8,1)\n",
    "X_train_knit, X_test_knit, Y_train_knit, Y_test_knit = fabric_features(X_knit, Y_knit,8,1)\n",
    "X_train_linen, X_test_linen, Y_train_linen, Y_test_linen = fabric_features(X_linen, Y_linen,8,1)\n",
    "X_train_leather, X_test_leather, Y_train_leather, Y_test_leather = fabric_features(X_leather, Y_leather,8,1)\n",
    "X_train_outdoor, X_test_outdoor, Y_train_outdoor, Y_test_outdoor = fabric_features(X_outdoor, Y_outdoor,8,1)\n",
    "X_train_denim, X_test_denim, Y_train_denim, Y_test_denim = fabric_features(X_denim, Y_denim,8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a9b54c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import rand_score\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60928fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_fabric(X_train, X_test, Y_test, num_clusters):\n",
    "    kmeans = KMeans(n_clusters = num_clusters).fit(X_train)\n",
    "    labels = kmeans.predict(X_test)\n",
    "    rand = rand_score(Y_test, labels)\n",
    "    \n",
    "    return rand \n",
    "\n",
    "def GMM_fabric(X_train, X_test, Y_test, num_clusters):\n",
    "    gm = GaussianMixture(n_components=num_clusters).fit(X_train)\n",
    "    labels = gm.predict(X_test)\n",
    "    rand = rand_score(Y_test, labels)\n",
    "    \n",
    "    return rand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fd92b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_rand_fleece = kmeans_fabric(X_train_fleece, X_test_fleece, Y_test_fleece, 2)\n",
    "gmm_rand_fleece = GMM_fabric(X_train_fleece, X_test_fleece, Y_test_fleece, 2)\n",
    "\n",
    "km_rand_knit = kmeans_fabric(X_train_knit, X_test_knit, Y_test_knit, 2)\n",
    "gmm_rand_knit = GMM_fabric(X_train_knit, X_test_knit, Y_test_knit, 2)\n",
    "\n",
    "km_rand_linen = kmeans_fabric(X_train_linen, X_test_linen, Y_test_linen, 3)\n",
    "gmm_rand_linen = GMM_fabric(X_train_linen, X_test_linen, Y_test_linen, 3)\n",
    "\n",
    "km_rand_leather = kmeans_fabric(X_train_leather, X_test_leather, Y_test_leather, 3)\n",
    "gmm_rand_leather = GMM_fabric(X_train_leather, X_test_leather, Y_test_leather, 3)\n",
    "\n",
    "km_rand_outdoor = kmeans_fabric(X_train_outdoor, X_test_outdoor, Y_test_outdoor, 2)\n",
    "gmm_rand_outdoor = GMM_fabric(X_train_outdoor, X_test_outdoor, Y_test_outdoor, 2)\n",
    "\n",
    "km_rand_denim = kmeans_fabric(X_train_denim, X_test_denim, Y_test_denim, 2)\n",
    "gmm_rand_denim = GMM_fabric(X_train_denim, X_test_denim, Y_test_denim, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad88455c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fleece\n",
      "KMeans\t: 0.5282146160962072\n",
      "GMM\t: 0.4431082331174838\n",
      "\n",
      "knit\n",
      "KMeans\t: 0.6516516516516516\n",
      "GMM\t: 0.6516516516516516\n",
      "\n",
      "linen\n",
      "KMeans\t: 0.6291291291291291\n",
      "GMM\t: 0.6306306306306306\n",
      "\n",
      "leather\n",
      "KMeans\t: 0.5781512605042017\n",
      "GMM\t: 0.5764705882352941\n",
      "\n",
      "outdoor\n",
      "KMeans\t: 0.4974257425742574\n",
      "GMM\t: 0.500990099009901\n",
      "\n",
      "denim\n",
      "KMeans\t: 0.543859649122807\n",
      "GMM\t: 0.6491228070175439\n"
     ]
    }
   ],
   "source": [
    "print('fleece')\n",
    "print('KMeans\\t:', km_rand_fleece)\n",
    "print('GMM\\t:', gmm_rand_fleece)\n",
    "\n",
    "print('')\n",
    "print('knit')\n",
    "print('KMeans\\t:', km_rand_knit)\n",
    "print('GMM\\t:', gmm_rand_knit)\n",
    "\n",
    "print('')\n",
    "print('linen')\n",
    "print('KMeans\\t:',km_rand_linen)\n",
    "print('GMM\\t:', gmm_rand_linen)\n",
    "\n",
    "print('')\n",
    "print('leather')\n",
    "print('KMeans\\t:', km_rand_leather)\n",
    "print('GMM\\t:', gmm_rand_leather)\n",
    "\n",
    "\n",
    "print('')\n",
    "print('outdoor')\n",
    "print('KMeans\\t:', km_rand_outdoor)\n",
    "print('GMM\\t:', gmm_rand_outdoor)\n",
    "\n",
    "\n",
    "print('')\n",
    "print('denim')\n",
    "print('KMeans\\t:', km_rand_denim)\n",
    "print('GMM\\t:', gmm_rand_denim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb71546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b4a0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
